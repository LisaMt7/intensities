<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Intensity | Audio Visualization</title>
  <!-- <script src="https://cdn.jsdelivr.net/npm/brainsatplay-components"></script> -->
</head>

<style>

* {
  box-sizing: border-box;
}

  html, body {
    margin: 0px;
    font-family: sans-serif;
  }

  #overlay {
    opacity: 0;
    width: 100vw;
    height: 100vh;
    transition: 0.5s;
    position: fixed;
    top: 0;
    left: 0;
    pointer-events: none;
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1;
    font-size: 30px;
    font-weight: bold;
    /* background: black; */
  }

  #overlay.open {
    opacity: 1;
    pointer-events: all;
    backdrop-filter: blur(5px);
  }

  .disabled {
    pointer-events: none;
    opacity: 0.5;
  }

  body {
    display: grid;
    grid-template-columns: 1fr 300px;
    grid-template-rows: 75px 1fr 75px;
    grid-template-areas: 
            "nav nav nav"
            "main main side"
            "foot foot side";

    width: 100vw;
    height: 100vh;
  }

  nav, footer {
    z-index: 2;
    padding: 20px;
    height: 75px;
    background: black;
    color: white;
    font-weight: bold;
    display:flex;
    align-items: center;
    /* justify-content: center; */
  }

  nav {
    grid-area: nav;
  }

  section {
    padding: 25px;
  }

  video {
    width: 100%;
  }

  footer {
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    font-size: 70%;
    font-weight: normal;
    grid-area: footer;
  }

  #main {
    grid-area: main;
    display: flex;
    flex-wrap: wrap;
    display: grid;
  }
  
  #main > div {
    max-width: 400px;
  }

  #sidebar {
    background: rgb(234, 234, 234);
    padding: 10px;
    grid-area: auto;
    grid-area: side;
    height: 100%;
    width: 100%;
  }

</style>

<body>
  <nav>Intensity</nav>
  <div id="overlay">Loading file...</div>

  <!-- Interactive Sidebar -->
  <div id="sidebar">
    <h3>Controls</h3>
    <h4>Real-Time Data</h4>
    <button id="start">Start Data Acquisition</button>

    <h5>Audio Input</h5>
    <select id="in"></select>

    <h5>Audio Output</h5>
    <select id="out"></select>

    <h5>Video Input</h5>
    <select id="video"></select>

    <h4>Upload Files</h4>
    <fieldset>
      <input type="file" id="files" accept="audio/*, video/*" />
    </fieldset>
  </div>

  <!-- Main Visualization Area -->
  <section id="main">
  </section>

  <footer>Garrett Flynn and Lisa MÃ¼ller-Trede | 2022</footer>
</body>

<script type="module">

  // import * as components from "./dist/index.esm.js"
  import * as components from "https://cdn.jsdelivr.net/npm/brainsatplay-components@latest/dist/index.esm.js"

  // Bypass the usual requirement for user action
  const start = document.getElementById('start')
  const audioInputSelect = document.getElementById('in')
  const audioOutputSelect = document.getElementById('out')
  const videoSelect = document.getElementById('video')
  var fileInput = document.getElementById('files');
  var main = document.getElementById('main');
  var overlay = document.getElementById('overlay');

  navigator.mediaDevices.enumerateDevices()
    .then(gotDevices)
  // .catch(errorCallback);


  const context = new AudioContext();
  let self = false

  const sourceRegistry = {}

  // video.controls = true

  function gotDevices(deviceInfos) {
    console.log(deviceInfos)
    for (var i = 0; i !== deviceInfos.length; ++i) {
      var deviceInfo = deviceInfos[i];
      var option = document.createElement('option');
      option.value = deviceInfo.deviceId;
      if (deviceInfo.kind === 'audioinput') {
        option.text = deviceInfo.label ||
          'Microphone ' + (audioInputSelect.length + 1);
        audioInputSelect.appendChild(option);
      } else if (deviceInfo.kind === 'audiooutput') {
        option.text = deviceInfo.label || 'Speaker ' +
          (audioOutputSelect.length + 1);
        audioOutputSelect.appendChild(option);
      } else if (deviceInfo.kind === 'videoinput') {
        option.text = deviceInfo.label || 'Camera ' +
          (videoSelect.length + 1);
        videoSelect.appendChild(option);
      }
    }
  }

  const createAnalyser = () => {
    const analyser = context.createAnalyser();
    analyser.smoothingTimeConstant = 0.2;
    analyser.fftSize = 1024;
    analyser.minDecibels = -127;
    analyser.maxDecibels = 0;
    return analyser
  }


  const analyse = (o) => {
      // Analyze the Data
      let volumeCallback = null;
      let volumeInterval = null;
      const frequencies = new Uint8Array(o.analyser.frequencyBinCount);
      let raw = new Uint8Array(1) // Only get the latest
      const getData = () => {
        o.analyser.getByteFrequencyData(frequencies);
        o.analyser.getByteTimeDomainData(raw)
        console.log(frequencies)
        const arr = Array.from(raw)
        o.timeseries.data = [arr]
        o.spectrogram.data = Array.from(frequencies)
      };

      setInterval(getData, 100); // Get Data Every 100ms
  }

  const onStreamSource = (src, inputs={}) => {

      src.connect(filterNode); // Connect to top of Web Audio API Context

      // TODO: Split tracks from video
      const channels = src.numberOfChannels ?? src.buffer?.numberOfChannels
      console.log('channels', src, channels, inputs.stream, inputs.video)
      if (channels > 1) {
        var splitter = context.createChannelSplitter(channels);
        analyser.connect(splitter); // Connect end of main graph to the Splitter graph
        var merger = context.createChannelMerger(channels);

        for (let i = 0; i < channels; i++){
          const o = spawnStreamDisplay(count, inputs) // Create Display
          o.container.insertAdjacentHTML('afterbegin',`<h3>Channel ${i}`)
          const gainNode = context.createGain();
          gainNode.gain.setValueAtTime(1.0, context.currentTime);
          o.analyser = createAnalyser()
          splitter.connect(analyser, i) // Connect Analyser to Channel i
          o.analyser.connect(gainNode);
          gainNode.connect(merger, 0, i) // Merge split inputs
          analyse(o) // Start analysis
          count++
        }
        if (!self) merger.connect(context.destination); // Output to the speakers
      } else {
        const o = spawnStreamDisplay(count, inputs) // Create Display
        o.analyser = analyser
        if (!self) analyser.connect(context.destination)
        analyse(o) // Start analysis
      }

      if (video){
        video.onended = () => {
          src.disconnect();
          gainNode.disconnect();
          filterNode.disconnect()
        }
      }

      if (src.start instanceof Function) src.start()
  }

  const spawnStreamDisplay = (count, o = {}) => {
        const container = document.createElement('div')
        // if (!o.video) o.video = document.createElement('video')
        main.insertAdjacentElement('beforeend', container)

        if (o.video){
          container.insertAdjacentElement('beforeend', o.video)
          // Real-Time Input
          if (o.stream) {
            o.video.srcObject = o.stream
            o.video.controls = false
          } 
          else {
            o.video.controls = true
          }
          o.video.autoplay = true

        }

        
        sourceRegistry[count] = {
            container,
            video: o.video,
            stream: o.stream,
            spectrogram: new components.streams.data.Spectrogram(),
            timeseries: new components.streams.data.TimeSeries(),
        }

        container.insertAdjacentElement('beforeend', sourceRegistry[count].spectrogram)
        container.insertAdjacentElement('beforeend', sourceRegistry[count].timeseries)
        return sourceRegistry[count]
    }


  let count = 0

  fileInput.onchange = async (ev) => {
    count = 0 // Reset count with new file...
    for (let file of fileInput.files) {
      const type = file.type.split('/')[0]
      let source, video;

      if (type === 'video'){
          video = document.createElement('video')
          video.src = URL.createObjectURL(file)
          source = context.createMediaElementSource(video);
      } else {
        source = await onAudio(file);
      }

      onStreamSource(source, {video}) // Get Audio Features + Wire Audio Analysis + Create Display
      // count added in here
    }

    main.style.gridTemplateColumns = `repeat(${count},1fr)`
  }

  // Setup Analysis
  var analyser = context.createAnalyser();
    analyser.smoothingTimeConstant = 0.2;
    analyser.fftSize = 1024;
    analyser.minDecibels = -127;
    analyser.maxDecibels = 0;

    var filterNode = context.createBiquadFilter();
    filterNode.type = 'highpass';
    filterNode.frequency.value = 7000;

    var gainNode = context.createGain(); // Create a gain node to change audio volume.
    gainNode.gain.value = 1.0;

      
  filterNode.connect(gainNode);
      // microphone.connect(gainNode);
      gainNode.connect(analyser);
      // analyser.connect(context.destination);

      // var source = context.createBufferSource();
      // source.buffer = data;


  start.onclick = () => {

    self = true
    navigator.mediaDevices.getUserMedia({
      audio: {
        deviceId: { exact: audioInputSelect.value }
      }, 
      video: { exact: videoSelect.value }
    }).then((stream) => {
      const video = document.createElement('video')
      const microphone = context.createMediaStreamSource(stream);
      onStreamSource(microphone, {video, stream})
    })
  }


  // var reader1 = new FileReader();

  const onAudio =(file) => {
  return new Promise((resolve, reject) => {
    let reader = new FileReader();

    reader.onload = (ev) => {

      overlay.classList.add('open')
      context.decodeAudioData(ev.target.result, (data) => {
        overlay.classList.remove('open')
        const source = context.createBufferSource();
        source.buffer = data;
        resolve(source);
      })
    };

    function handleEvent(event) {
    console.log(`${event.type}: ${event.loaded} bytes transferred\n`)

    if (event.type === "load") {
        // preview.src = reader.result;
    }
}

    // reader.addEventListener('loadstart', handleEvent);
    // reader.addEventListener('load', handleEvent);
    // reader.addEventListener('loadend', handleEvent);
    // reader.addEventListener('progress', handleEvent);
    reader.addEventListener('error', handleEvent);
    // reader.addEventListener('abort', handleEvent);

    reader.readAsArrayBuffer(file);
  })
}

</script>

</html>