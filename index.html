<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Audio Visualization</title>
  <!-- <script src="https://cdn.jsdelivr.net/npm/brainsatplay-components"></script> -->
</head>

<style>

* {
  box-sizing: border-box;
}

  html, body {
    margin: 0px;
    font-family: sans-serif;
  }

  body {
    display: grid;
    grid-template-columns: 1fr 300px;
    grid-template-rows: 75px 1fr 75px;
    grid-template-areas: 
            "nav nav nav"
            "main main side"
            "foot foot side";

    width: 100vw;
    height: 100vh;
  }

  nav, footer {
    padding: 20px;
    height: 75px;
    background: black;
    color: white;
    font-weight: bold;
    display:flex;
    align-items: center;
    /* justify-content: center; */
  }

  nav {
    grid-area: nav;
  }

  section {
    padding: 25px;
  }

  video {
    width: 100%;
  }

  footer {
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    font-size: 70%;
    font-weight: normal;
    grid-area: footer;
  }

  #main {
    grid-area: main;
    display: flex;
    flex-wrap: wrap;
    display: grid;
  }
  
  #main > div {
    max-width: 400px;
  }

  #sidebar {
    background: rgb(234, 234, 234);
    padding: 10px;
    grid-area: auto;
    grid-area: side;
    height: 100%;
    width: 100%;
  }

</style>

<body>
  <nav>Intensity</nav>

  <!-- Interactive Sidebar -->
  <div id="sidebar">
    <h3>Controls</h3>
    <h4>Real-Time Data</h4>
    <button id="start">Start</button>

    <h5>Audio Input</h5>
    <select id="in"></select>

    <h5>Audio Output</h5>
    <select id="out"></select>

    <h5>Video Input</h5>
    <select id="video"></select>

    <h4>Upload Files</h4>
    <fieldset>
      <input type="file" id="files" accept="audio/*, video/*" />
    </fieldset>
  </div>

  <!-- Main Visualization Area -->
  <section id="main">
  </section>

  <footer>Garrett Flynn and Lisa MÃ¼ller-Trede | 2022</footer>
</body>

<script type="module">

  // import * as components from "./dist/index.esm.js"
  import * as components from "https://cdn.jsdelivr.net/npm/brainsatplay-components@latest/dist/index.esm.js"

  // Bypass the usual requirement for user action
  const start = document.getElementById('start')
  const audioInputSelect = document.getElementById('in')
  const audioOutputSelect = document.getElementById('out')
  const videoSelect = document.getElementById('video')
  var fileInput = document.getElementById('files');
  var main = document.getElementById('main');

  navigator.mediaDevices.enumerateDevices()
    .then(gotDevices)
  // .catch(errorCallback);


  const context = new AudioContext();

  const sourceRegistry = {}

  // video.controls = true

  function gotDevices(deviceInfos) {
    console.log(deviceInfos)
    for (var i = 0; i !== deviceInfos.length; ++i) {
      var deviceInfo = deviceInfos[i];
      var option = document.createElement('option');
      option.value = deviceInfo.deviceId;
      if (deviceInfo.kind === 'audioinput') {
        option.text = deviceInfo.label ||
          'Microphone ' + (audioInputSelect.length + 1);
        audioInputSelect.appendChild(option);
      } else if (deviceInfo.kind === 'audiooutput') {
        option.text = deviceInfo.label || 'Speaker ' +
          (audioOutputSelect.length + 1);
        audioOutputSelect.appendChild(option);
      } else if (deviceInfo.kind === 'videoinput') {
        option.text = deviceInfo.label || 'Camera ' +
          (videoSelect.length + 1);
        videoSelect.appendChild(option);
      }
    }
  }
  const onFreqs = (frequencies, i) => {
    sourceRegistry[i].spectrogram.data = Array.from(frequencies)
  }

  const onAudio = (src) => {
    reader1.readAsArrayBuffer(src);
  }

  const onStreamSource = (src, stream, i) => {
      src.connect(filterNode);

      stream.onended = () => {
        src.disconnect();
        gainNode.disconnect();
        filterNode.disconnect()
      }

      // Show Audio Volume
      let volumeCallback = null;
      let volumeInterval = null;
      const frequencies = new Uint8Array(analyser.frequencyBinCount);
      let raw = new Uint8Array(1) // Only get the latest
      const getData = () => {
        analyser.getByteFrequencyData(frequencies);
        analyser.getByteTimeDomainData(raw)
        const arr = Array.from(raw)
        sourceRegistry[i].timeseries.data = [arr]
        onFreqs(frequencies, i)
      };

      setInterval(getData, 100); // Get Data Every 100ms
  }

  var reader1 = new FileReader();

  const spawnStream = (count,stream) => {
    const container = document.createElement('div')
        const video = document.createElement('video')
        video.controls = true
        container.insertAdjacentElement('beforeend', video)
        main.insertAdjacentElement('beforeend', container)

        sourceRegistry[count] = {
            video,
            stream,
            spectrogram: new components.streams.data.Spectrogram(),
            timeseries: new components.streams.data.TimeSeries(),
        }

        container.insertAdjacentElement('beforeend', sourceRegistry[count].spectrogram)
        container.insertAdjacentElement('beforeend', sourceRegistry[count].timeseries)
  }

  fileInput.onchange = (ev) => {

    // TODO: Check if audio or video
    // If video, then get the audio
    let count = 0
    for (let file of fileInput.files) {
      switch (file.type.split('/')[0]) {
        case 'video':
          spawnStream(count)
          video.src = URL.createObjectURL(file)
          var source = context.createMediaElementSource(video);
          // video.autoplay = true
          onStreamSource(source, video, count)
          break;
        default:
          onAudio(file);
          break;
      }
      count++
    }

    main.style.gridTemplateColumns = `repeat(${count},1fr)`
  }

  // Setup Analysis
  var analyser = context.createAnalyser();
      analyser.smoothingTimeConstant = 0.2;
      analyser.fftSize = 1024;
      analyser.minDecibels = -127;
      analyser.maxDecibels = 0;

      var filterNode = context.createBiquadFilter();
      filterNode.type = 'highpass';
      filterNode.frequency.value = 7000;

      var gainNode = context.createGain(); // Create a gain node to change audio volume.
      gainNode.gain.value = 1.0;

      
  filterNode.connect(gainNode);
      // microphone.connect(gainNode);
      gainNode.connect(analyser);
      analyser.connect(context.destination);

  start.onclick = () => {

    navigator.mediaDevices.getUserMedia({
      audio: {
        deviceId: { exact: audioInputSelect.value }
      }, 
      video: { exact: videoSelect.value }
    }).then((stream) => {
      const microphone = context.createMediaStreamSource(stream);
      spawnStream(0, stream)
      onStreamSource(microphone, stream, 0)
    })
  }

  reader1.onload = (ev) => {

    context.decodeAudioData(ev.target.result, (data) => {

      var source = context.createBufferSource();
      source.buffer = data;
      var splitter = context.createChannelSplitter(2);
      source.connect(splitter);
      var merger = context.createChannelMerger(2);

      // Reduce the volume of the left channel only
      var gainNode = context.createGain();
      gainNode.gain.setValueAtTime(0.5, context.currentTime);
      splitter.connect(gainNode, 0);

      // Connect the splitter back to the second input of the merger: we
      // effectively swap the channels, here, reversing the stereo image.
      gainNode.connect(merger, 0, 1);
      splitter.connect(merger, 1, 0);

      // merger.connect(this.out)
      merger.connect(context.destination);
    })
  }

</script>

</html>